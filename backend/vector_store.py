import faiss
import pandas as pd
import os
import pickle
import numpy as np

from backend.embedder import embed_texts

INDEX_PATH = "data/faiss_index.bin"
META_PATH = "data/job_metadata.pkl"

def build_faiss_index(csv_path: str):
    print("ðŸ”¹ Loading jobs CSV...")
    df = pd.read_csv(csv_path)

    print(f"ðŸ”¹ Loaded {len(df)} jobs")

    texts = (
        df["role"] + " " +
        df["skills"] + " " +
        df["description"]
    ).tolist()

    print("ðŸ”¹ Generating embeddings...")
    embeddings = embed_texts(texts)

    dimension = len(embeddings[0])
    print(f"ðŸ”¹ Embedding dimension: {dimension}")

    index = faiss.IndexFlatL2(dimension)

    # âœ… CORRECT FAISS ADD
    index.add(np.array(embeddings).astype("float32"))

    os.makedirs("data", exist_ok=True)

    print("ðŸ”¹ Saving FAISS index...")
    faiss.write_index(index, INDEX_PATH)

    print("ðŸ”¹ Saving metadata...")
    metadata = df.to_dict(orient="records")
    with open(META_PATH, "wb") as f:
        pickle.dump(metadata, f)

    print("âœ… FAISS index built and saved successfully.")


if __name__ == "__main__":
    print("ðŸš€ Starting FAISS index builder...")
    build_faiss_index("data/jobs.csv")
